---
title: k8s源码
date: 2020-03-02 21:40:33
categories: 技术博客
tags:
    - IT
toc: true
thumbnail: 
---

​        k8s源码

<!--more-->

## Kubernetes Project Layout设计

Kubernetes项目由Go语言编写。Go语言官方对项目的结构设计没有强制要求，早期的Go语言开发者都喜欢将包文件代码放置在项目的src/目录下，如nsqio开源项目，开发者喜欢将入口文件放入apps/目录。不同开发者的喜好不同，这导致开源项目的结构设计没有统一标准。

后来Go语言社区提出Standard Go Project Layout方案，以对Go语言项目目录结构进行划分。目前该标准已经成为众多Go语言开源项目的选择。

根据Standard Go Project Layout方案，我们对标一下Kubernetes的Project Layout设计

由于Kubernetes项目全球开发者众多，这导致早期的代码包较多，尤其是kube-apiserver项目，其内部所引用的代码包特别多。随着Kubernetes系统版本的迭代，逐渐将部分包进行了合并，其中staging/目录为核心包暂存目录，该目录下的核心包多以软连接的方式链接到vendor/k8s.io目录。

Kubernetes系统组件较多，各组件的代码入口main结构设计风格高度一致

从代码入口main结构来看，各组件的目录结构、文件命名都保持高度一致。假设需要新增一个组件，我们甚至可以复制原有的组件代码，只需简单修改一下就可以将其运行起来。每个组件的初始化过程也非常类似

main结构中定义了进程运行的周期，包括从进程启动、运行到退出的过程。以kube-apiserver组件为例

（1）rand.Seed：组件中的全局随机数生成对象。

（2）app.NewCommand：实例化命令行参数。通过flags对命令行参数进行解析并存储至Options对象中。

（3）logs.InitLogs：实例化日志对象，用于日志管理。

（4）command.Execute：组件进程运行的逻辑。运行前通过Complete函数填充默认参数，通过Validate函数验证所有参数，最后通过Run函数持久运行。只有当进程收到退出信号时，进程才会退出。

Kubernetes其他组件的cmd设计与之类似，故不再重复描述，后续章节会针对每个组件详细描述其启动过程。

## Kubenetes构建过程

构建过程是指“编译器”读取Go语言代码文件，经过大量的处理流程，最终产生一个二进制文件的过程；也就是将人类可读的代码转化成计算机可执行的二进制代码的过程。

手动构建Kubernetes二进制文件是一件非常麻烦的事情，尤其是对于较为复杂的Kubernetes大型程序来说。Kubernetes官方专门提供了一套编译工具，使构建过程变得更容易。

Kubernetes构建方式可以分为3种，分别是本地环境构建、容器环境构建、Bazel环境构建

首先，将Kubernetes源码通过Go语言工具下载下来，并切换至Kubernetes 1.14代码版本，命令示例如下

```shell
$ go get -d k8s.io/kubernetes
$ cd $GOPATH/src/k8s.io/kubernetes
$ git checkout -b release-1.14 remotes/origin/release-1.14
```

注意：构建Kubernetes 1.14版本，需要使用Go 1.12或更高版本。不同的Kubernetes版本对应的Go语言版本也不同。

从cloc代码统计命令的输出可以看到，Kubernetes 1.14拥有大约357万行代码，其中Go语言代码占303万行，这是非常庞大的代码量。当然，其中也包含通过代码生成器生成的Go语言代码文件

### 本地环境构建

执行make或make all命令，会编译Kubernetes的所有组件，组件二进制文件输出的相对路径是_output/bin/。如果我们需要对Makefile的执行过程进行调试，可以在make命令后面加-n参数，输出但不执行所有执行命令，这样可以展示更详细的构建过程。假设我们想单独构建某一个组件，如kubectl组件，则需要指定WHAT参数，命令示例如下

```shell
$ make WHAT=cmd/kubectl
```

一切都始于Makefile

Go语言开发者习惯于手动执行go build（构建）和go test（单元测试）命令，因为Go语言为开发者提供了便捷的工具。但在一些生产环境或复杂的大型项目中，这是一种不好的开发习惯，而在实际的Go语言开发项目中使用Makefile是好的约束规范。

Makefile是一个非常有用的自动化工具，可以用来构建和测试Go语言应用程序。Makefile还适用于大多数编程语言，如C++等。在Kubernetes的源码根目录中，有两个与Makefile相关的文件，分别介绍如下。

● Makefile：顶层Makefile文件，描述了整个项目所有代码文件的编译顺序、编译规则及编译后的二进制输出等。

● Makefile.generated_files：描述了代码生成的逻辑。

通过make help命令，可以展示出所有可用的构建选项，从构建到测试的选项都有。首先，看一下make all命令在Makefile中的定义

若要在Kubernetes的Makefile文件中定义，其步骤为：

第1步，执行generated_files命令（在Makefile中称其为目标），用于代码生成（Code Generation）；

第2步，通过调用hack/make-rules/build.sh脚本开始执行构建操作，其中的$（WHAT）参数表示要指定构建的Kubernetes组件名称，不指定该参数则默认构建Kubernetes的所有组件。

本地构建过程

通过调用hack/make-rules/build.sh脚本开始构建组件，传入要构建的组件名称，不指定组件名称则构建所有组件。hack/make-rules/build.sh代码示例如下：

```shell
kube::golang::build_binaries "$@"
```

build_binaries接收构建的组件名称，设置构建所需的环境及一些编译时所需的Go flags选项，然后通过go install构建组件

```shell
go install "${build_args[@]}" "$@"
```

在go install命令执行完成后，二进制输出的目录为_output/bin/。通过make all命令构建所有组件，二进制输出如下（只展示了核心组件）

最后，可以使用make clean命令来清理构建环境。

### 容器环境构建

通过容器（Docker）进行Kubernetes构建也非常简单，Kubernetes提供了两种容器环境下的构建方式：make release和make quick-release，它们之间的区别如下

● make release：构建所有的目标平台（Darwin、Linux、Windows），构建过程会比较久，并同时执行单元测试过程。

● make quick-release：快速构建，只构建当前平台，并略过单元测试过程。

make quick-release与make release相比多了两个变量，即KUBE_RELEASE_RUN_TESTS和KUBE_FASTBUILD。KUBE_RELEASE_RUN_TESTS变量，将其设为n则跳过运行单元测试；KUBE_FASTBUILD变量，将其设为true则跳过跨平台交叉编译。通过这两个变量可以实现快速构建，最终执行build/release.sh脚本，运行容器环境构建。

在容器环境构建过程中，有多个容器镜像参与其中，分别介绍如下。

● build容器（kube-cross）：即构建容器，在该容器中会对代码文件执行构建操作，完成后其会被删除。

● data容器：即存储容器，用于存放构建过程中所需的所有文件。

● rsync容器：即同步容器，用于在容器和主机之间传输数据，完成后其会被删除。

Kubernetes容器环境构建过程

kube::build::verify_prereqs：进行构建环境的配置及验证。该过程会检查本机是否安装了Docker容器环境，而对于Darwin平台，该过程会检查本机是否安装了docker-machine环境。

kube::build::build_image：根据Dockerfile文件构建容器镜像。Dockerfile文件来源于build/build-image/Dockerfile，

构建容器镜像的流程如下

● 通过mkdir命令创建构建镜像的文件夹（即_output/images/…）。

● 通过cp命令复制构建镜像所需的相关文件，如Dockerfile文件和rsyncd同步脚本等。

● 通过kube：：build：：docker_build函数，构建容器镜像。

● 通过kube：：build：：ensure_data_container函数，运行存储容器并挂载Volume。

● 通过kube：：build：：sync_to_container函数，运行同步容器并挂载存储容器的Volume，然后通过rsync命令同步Kubernetes源码到存储容器的Volume。

kube::build::run_build_command make cross：此时，容器构建环境已经准备好，下面开始运行构建容器并在构建容器内部执行构建Kubernetes源码的操作

kube::build::copy_output：使用同步容器，将编译后的代码文件复制到主机上。

kube::release::package_tarballs：进行打包，将二进制文件打包到_output目录中。

最终，代码文件以tar.gz压缩包的形式输出至_output/release-tars文件夹。

### Bazel环境构建

Bazel是Google公司开源的一个自动化软件构建和测试工具。Bazel使用分布式缓存和增量构建方法，使构建更加快速。其支持构建任务，包括运行编译器和链接器以生成可执行程序和库。Bazel与Make、Gradle及Maven等构建工具类似，但Bazel在构建速度、可扩展性、灵活性及跨语言和对不同平台的支持上更加出色。Bazel具有如下特性。

● 支持多语言：Bazel支持Java、Objective-C和C++等主流语言，并可以扩展支持任意的其他编程语言。

● 高级别的构建语言：项目以BUILD语言进行描述。BUILD是一种简洁的文本格式，可描述多个小而互相关联的库、二进制程序和测试程序组成的项目。

● 支持多平台：相同的工具和BUILD文件可以为不同架构或平台构建软件。

● 再现性：在BUILD文件中，必须明确为每个库、测试程序、二进制文件指定其直接依赖。在修改源码文件后，Bazel使用这个依赖信息就可以知道哪些东西必须重新构建，哪些任务可以并行执行。这意味着所有的构建都是以增量的形式构建的并能够每次都生成相同的结果。

● 可扩展性强：Bazel可以处理大型程序的构建；在Google公司内，一个二进制程序通常有超过100KB的源码文件，在代码文件没有被改动的情况下，构建过程大约需要200ms。

● 构建速度快：支持增量编译。对依赖关系进行了优化，从而支持并发执行。

但是如此优秀的Bazel为什么在开源软件中流行不起来，只能在Google内部大量使用呢？一方面是因为接入Bazel较为复杂；另一方面在于Google内部的代码库非常庞大（约有数百万行），Bazel支持多语言的构建系统为所有项目构建代码，将源码统一存放，使用统一的持续集成来运行所有的单元测试，因此在构建过程中性能问题是最关键的问题，而大部分公司很少遇到像Google这样进行大规模编译的性能问题。

比较有趣的是，在Go语言社区内有时也会争论Go语言项目是否应该使用go build/install或bazel build。目前Kubernetes已经支持使用Bazel进行构建和测试了，但尚未将Bazel作为默认的构建工具。

bazel常用make操作

● make bazel-build：构建所有二进制文件。

● make bazel-test：运行所有单元测试。

● make bazel-test-integration：运行所有集成测试。

● make bazel-release：在容器中进行构建。

单独构建kubectl

除根据Makefile中定义的make bazel操作外，我们也可以直接使用bazel命令，来对单独组件进行构建，

上述代码中的//cmd/kubectl/…在Bazel中被称为标记，用于指定需要构建的包名。若执行构建命令后输出如上信息，则表示构建成功，Bazel将构建后的二进制文件输出到根目录下的bazel-bin目录中。kubectl二进制文件的相对路径为bazel-bin/cmd/kubectl/。注意：Bazel目前不支持CGO的交叉编译。

注意：Bazel目前不支持CGO的交叉编译。

更新BUILD文件

每当开发者对Kubernetes代码进行更新迭代、添加或删除Go语言文件代码，以及更改Go import时，都必须更新各个包下的BUILD和BUILD.bazel文件，更新操作可通过运行hack/update-bazel.sh脚本自动完成

```shell
$ ./hack/update-bazel.sh
```

Bazel工作原理

Kubernetes源码的根目录下有一个WORKSPACE（工作区）文件，用于指定当前目录是Bazel的一个工作区域，该文件一般存放在项目根目录下。另外，项目中包含一个或多个BUILD文件，用于告诉Bazel如何进行构建。

Bazel工作原理大致分为3部分。

（1）加载与Target相关的BUILD文件。

（2）分析BUILD文件的内容，生成Action Graph。

（3）执行Action Graph，最后产出Outputs。

ABAC资源的BUILD文件内容如下

● load：需要使用哪个.bzl规则来编译当前Target。

● go_library：设置构建规则。

■ name：当前Target构建后的名称。

■ src：当前Target下被构建的源码文件。

■ deps：当前Target构建时依赖的静态库名称。

在Kubernetes项目代码中，BUILD文件可通过执行hack/update-bazel.sh脚本来自动生成。Bazel第一次构建时须生成Bazel Cache，时间较长，再次构建时无须再生成Bazel Cache，Bazel Cache有利于大大提高构建速度。注意：Bazel目前并非完全支持Kubernetes代码生成器，当前只有openapi-gen和go-bindata是支持的。

## Scheduler

Kubernetes scheduler独立运作与其他主要组件之外(例如API Server)，它连接API Server，watch观察，如果有PodSpec.NodeName为空的Pod出现，则开始工作，通过一定得筛选算法，筛选出合适的Node之后，向API Server发起一个绑定指示，申请将Pod与筛选出的Node进行绑定

scheduler的设计分为3个主要代码层级：

- `cmd/kube-scheduler/scheduler.go`: 这里的main()函数即是scheduler的入口，它会读取指定的命令行参数，初始化调度器框架，开始工作
- `pkg/scheduler/scheduler.go`: 调度器框架的整体代码，框架本身所有的运行、调度逻辑全部在这里
- `pkg/scheduler/core/generic_scheduler.go`: 上面是框架本身的所有调度逻辑，包括算法，而这一层，是调度器实际工作时使用的算法，默认情况下，并不是所有列举出的算法都在被实际使用，参考位于文件中的`Schedule()`函数

### cobra

github主页: https://github.com/spf13/cobra 主页的介绍是: Cobra是一个强大的用于创建现代化CLI命令行程序的库，用于生成应用程序和命令文件。众多高知名度的项目采用了它，例如我们熟悉的kubernetes和docker cobra创建的程序CLI遵循的模式是: `APPNAME COMMAND ARG --FLAG`，与常见的其他命令行程序一样，例如git: `git clone URL --bare`

安装

```shell
#最简单的安装方式，但毫无意外，事情并没有那么简单，我们的网络的问题，导致无法正常安装依赖，
go get -u github.com/spf13/cobra/cobra

#怎么办呢？先进入GOPATH中，手动安装报错缺失的两个依赖:
cd /Users/ywq/go/
mkdir -p src/golang.org/x
cd golang.org/x
git clone https://github.com/golang/text.git
git clone https://github.com/golang/sys.git

#然后执行:
go install github.com/spf13/cobra/cobra
matebook-x-pro:x ywq$ ls /Users/ywq/go/bin/cobra
/Users/ywq/go/bin/cobra
#安装完毕,记得把GOBIN加入PATH环境变量哦,否则无法直接运行cobra命令
```





### Pod优先级调度

在kubernetes v1.8版本之后可以指定pod优先级(v1alpha1)，若资源不足导致高优先级pod匹配失败，高优先级pod会转而将部分低优先级pod驱逐，以抢占低优先级pod的资源尽力保障自身能够调度成功，

pod优先级可以在调度的时候为高优先级的pod提供资源空间保障，若出现资源紧张的情况，则在其他约束规则允许的情况下，高优先级pod会抢占低优先级pod的资源。此功能在1.11版本以后默认开启，默认情况下pod的优先级是0，优先级值high is better



## Controller

Controller通过watch apiServer，循环地观察监控着某些特定的资源对象，获取它们当前的状态，对它们进行对比、修正、收敛，来使这些对象的状态不断靠近、直至达成在它们的声明语义中所期望的目标状态，这即是controller的作用。再通俗点来说，就是使资源对象的status当前状态达到spec的期望状态。



## API SERVER

APIServer提供了 k8s各类资源对象的CURD/watch、认证授权、准入控制等众多核心功能，在k8s中定位类似于大脑和心脏，它的功能包括：

- 提供了集群管理的REST API接口(包括资源CURD、认证授权、数据校验以及集群状态变更)；
- 是所有模块的数据交互和通信的枢纽，各模块的运作都依赖于APIServer
- 提供丰富多样的集群安全管控机制
- 直连后端存储(Etcd)，是唯一与存储后端直接通信的模块

如图所示，这是创建一个资源(Pod)实例过程中，控制层面所经过的调用过程

因此，APIServer无疑是各模块中 **最复杂、定位最核心、涉及面最广、代码量最大** 的模块。

APIServer的工作主要围绕着对各类资源对象的管控，因此，在开始阅读APIServer的源码之前，有必要笼统地列举一下它在运行中所用到的核心数据结构等基础性信息

### 基础结构信息

APIServer的工作主要围绕着对各类资源对象的管控，因此，在开始阅读APIServer的源码之前，有必要笼统地列举一下它在运行中所用到的核心数据结构等基础性信息

Group/Version/Kind/Resource

在K8s的设计中，resource是其最基础、最重要的概念，也是最小的管理单位，所有的管理对象都承载在一个个的resource实例上，为了实现这些resource的复杂管理逻辑，又进一步地将他们分组化、版本化，依照逻辑层次，形成了Group、Version、Kind、Resource核心数据结构：

- Group：资源组，也称APIGroup，常见的有core、apps、extensions等
- Version：资源版本，也称APIVersion，常见的有v1、v1beta1 (Resource可能属于拥有多个Version，这些version也会有优先级之分，例如deployment即属于apps/v1,又属于extensions/v1beta1，在不同k8s版本中，version的优先级可能会变化)
- Kind：资源种类，描述资源的类别，例如pod类别、svc类别等
- Resource：资源实例对象，也称为APIResource
- SubResource：子资源，部分资源实例会 有子资源，例如Deployment资源会拥有Status子资源
- CRD: Custom Resource Definitions，用户自定义资源类型

锚定形式

概念层面，在K8s中，常见的资源路径锚定形式为：///，例如deployment对应的路径是：apps/v1/deployments/status

官方通常通过缩写词**GVR**(GroupVersionKind)来描述一个资源的明确锚定位置(类似于绝对路径？)，同理，**GVK**(GroupVersionKind)锚定资源的明确所属类型，在项目代码中也经常用到，例如

资源结构体

而落实到代码中，每一种资源的结构体定义文件都位于其Group下的的types.go文件中，例如，Deployment资源的结构体定义在这里`pkg/apis/apps/types.go:268`

资源操作方法

概念层面，每种resource都有对应的管理操作方法，目前支持的有这几种

- get
- list
- create
- update
- patch
- delete
- deletecolletction
- watch

使用[]string结构来描述资源所对应的操作，而[]string终归只是描述，需要与实际的存储资源CRUD操作关联，因此，不难猜测，每种string描述的方法会map到具体的方法上去，结构类似于: map[string]Function

内部和外部Version

在k8s的设计中，资源版本分外部版本(external)和内部版本(internal)之分，外部版本(例如v1/v1beta1/v1beta2)提供给外部使用，而对应的内部版本仅在APIServer内部使用

区分内外版本的作用：

- 提供不同版本之间的转换功能，例如从v1beta1-->v1的过程实际是v1beta1--> internal -->v1，转换函数会注册到scheme表中
- 减少复杂度，方便版本维护，避免维护多个版本的对应代码，实际APIServer端处理的都是转换后的内部版本
- 不同外部版本资源之间的字段/功能可能存在些许差异，而内部版本包含所有版本的字段/功能，这为它作为外部资源版本之间转换的桥梁提供了基础。

Schema注册表

每一种Resource都有对应的Kind，为了更便于分类管理这些资源，APIServer设计了一种名为scheme的结构体，类似于注册表，运行时数据存放内存中，提供给各种资源进行注册，scheme有如下作用：

- 提供资源的版本转换功能
- 提供资源的序列化/反序列化功能

Scheme支持注册两种类型的资源：

- UnversionedType 无版本资源。这个在现版本的k8s中使用非常少，可以忽略
- VersionedType 几乎所有的资源都是携带版本的，是常用的类型

注册方法

scheme表提供两个注册方法：`AddKnownTypes` | `AddKnownTypeWithName` ，使用reflect反射的方式获取type obj的gvk然后进行注册

序列化和反序列化

APIServer对资源的描述支持yaml和json格式，分别对应不同的Serializer，Serializer内置有bool类型的yaml字段，来辨别是否是yaml Serializer。

序列化代码位于：`vendor/k8s.io/apimachinery/pkg/runtime/serializer/json/json.go:223`

可以得知，默认以json格式响应，而对于yaml格式，先将其转换为json格式，再转换回yaml格式响应

反序列化代码：`vendor/k8s.io/apimachinery/pkg/runtime/serializer/json/json.go:86`

go-restful

k8s选用的Restful框架是go-restful，简单说明一下go-restful的结构，辅助后面对于APIServer工作流程的理解。

go-restful层级结构概念自顶上下依次有:

- Container: 一个Container就是一个独立的http server，可拥有独立的地址端口组合(类似nginx的server层级)
- WebService： 大粒度的分类，某一类别的服务可归属到同一个WebService中，其下包含多个Route
- Route: 每个Route对应具体的uri路径，将该路径路由到对应的handler函数上

### 预启动和启动流程

资源注册

scheme是一种内存型的注册表，提供给各类gvk进行注册。在APIServer http服务启动前的第一步，就是将所支持的gvk注册到scheme中，后面的步骤会依赖scheme注册表信息。

值得注意的是，并没有函数方法来显示地注册scheme，而是通过go语言的包导入init机制来初始化注册的

认证配置

APIServer支持如下的认证策略：

- X509 Client Certs
- Static Token File
- Bootstrap Tokens
- Service Account Tokens
- OpenID Connect Tokens(OIDC)
- Webhook Token Authentication
- Authenticating Proxy

### 认证机制

所有 Kubernetes 集群都有两类用户：由 Kubernetes 管理的**服务账号**和**普通用户**。

其中服务账号(ServiceAccount)是提供给集群中的程序使用，以Secret资源保存凭据，挂载到pod中，从而允许集群内的服务调用k8s API。

而普通用户，尚不支持使用API创建，一般由证书创建，Kubernetes 使用证书中的 'subject' 的通用名称（Common Name）字段（例如，"/CN=bob"）来 确定用户名。

Kubernetes 使用身份认证插件利用客户端证书、持有者令牌（Bearer Token）、身份认证代理（Proxy） 或者 HTTP 基本认证机制来认证 API 请求的身份。HTTP 请求发给 API 服务器时， 插件会将以下属性关联到请求本身：

- 用户名：用来辩识最终用户的字符串。常见的值可以是 `kube-admin` 或 `jane@example.com`。
- 用户 ID：用来辩识最终用户的字符串，旨在比用户名有更好的一致性和唯一性。
- 用户组：取值为一组字符串，其中各个字符串用来标明用户是某个命名的用户逻辑集合的成员。 常见的值可能是 `system:masters` 或者 `devops-team` 等。
- 附加字段：一组额外的键-值映射，键是字符串，值是一组字符串；用来保存一些鉴权组件可能 觉得有用的额外信息。

与其它身份认证协议（LDAP、SAML、Kerberos、X509 的替代模式等等）都可以通过 使用一个[身份认证代理](https://kubernetes.io/zh/docs/reference/access-authn-authz/authentication/#authenticating-proxy)或 [身份认证 Webhoook](https://kubernetes.io/zh/docs/reference/access-authn-authz/authentication/#webhook-token-authentication)来实现。

认证流程

RequestHeader认证

是一种代理认证方式，需要再apiserver启动时以参数形式配置，来看看官方的介绍：

API 服务器可以配置成从请求的头部字段值（如 `X-Remote-User`）中辩识用户。 这一设计是用来与某身份认证代理一起使用 API 服务器，代理负责设置请求的头部字段值。

- `--requestheader-username-headers` 必需字段，大小写不敏感。用来设置要获得用户身份所要检查的头部字段名称列表（有序）。第一个包含数值的字段会被用来提取用户名。
- `--requestheader-group-headers` 可选字段，在 Kubernetes 1.6 版本以后支持，大小写不敏感。 建议设置为 "X-Remote-Group"。用来指定一组头部字段名称列表，以供检查用户所属的组名称。 所找到的全部头部字段的取值都会被用作用户组名。
- `--requestheader-extra-headers-prefix` 可选字段，在 Kubernetes 1.6 版本以后支持，大小写不敏感。 建议设置为 "X-Remote-Extra-"。用来设置一个头部字段的前缀字符串，API 服务器会基于所给 前缀来查找与用户有关的一些额外信息。这些额外信息通常用于所配置的鉴权插件。 API 服务器会将与所给前缀匹配的头部字段过滤出来，去掉其前缀部分，将剩余部分 转换为小写字符串并在必要时执行[百分号解码](https://tools.ietf.org/html/rfc3986#section-2.1) 后，构造新的附加信息字段键名。原来的头部字段值直接作为附加信息字段的值。

BasicAuth认证

BasicAuth是一种简单的基础http认证，用户名、密码写入http请求头中，用base64编码，防君子不防小人，安全性较低，因此很少使用。快速略过

启动apiserver时，使用--basic-auth-file参数指定csv文件，csv里面以逗号切割，存放用户名、密码、uid

X509 CA认证

又称TLS双向认证，APIServer启动时使用--client-ca-file指定客户端的证书文件，用作请求的认证

BearerToken认证



## 鉴权

请求在通过认证之后，请求将进入鉴权环节

审查请求属性

Kubernetes 仅审查以下 API 请求属性：

- **用户** - 身份验证期间提供的 `user` 字符串。
- **组** - 经过身份验证的用户所属的组名列表。
- **额外信息** - 由身份验证层提供的任意字符串键到字符串值的映射。
- **API** - 指示请求是否针对 API 资源。
- **请求路径** - 各种非资源端点的路径，如 `/api` 或 `/healthz`。
- **API 请求动词** - API 动词 `get`、`list`、`create`、`update`、`patch`、`watch`、 `proxy`、`redirect`、`delete` 和 `deletecollection` 用于资源请求。 要确定资源 API 端点的请求动词，请参阅 [确定请求动词](https://kubernetes.io/zh/docs/reference/access-authn-authz/authorization/#determine-the-request-verb)。
- **HTTP 请求动词** - HTTP 动词 `get`、`post`、`put` 和 `delete` 用于非资源请求。
- **Resource** - 正在访问的资源的 ID 或名称（仅限资源请求）- 对于使用 `get`、`update`、`patch` 和 `delete` 动词的资源请求，你必须提供资源名称。
- **子资源** - 正在访问的子资源（仅限资源请求）。
- **名字空间** - 正在访问的对象的名称空间（仅适用于名字空间资源请求）。
- **API 组** - 正在访问的 [API 组](https://kubernetes.io/zh/docs/concepts/overview/kubernetes-api/#api-groups) （仅限资源请求）。空字符串表示[核心 API 组](https://kubernetes.io/zh/docs/reference/using-api/#api-groups)

鉴权策略

目前支持6种鉴权策略，每种鉴权策略对应一个鉴权器，使用的鉴权策略需要在APIServer启动时以参数`--authorization-mode`的形式指定，多种策略同时指定时使用','号连接：

策略分类有：

- `--authorization-mode=ABAC` 基于属性的访问控制（ABAC）模式允许你 使用本地文件配置策略。
- `--authorization-mode=RBAC` 基于角色的访问控制（RBAC）模式允许你使用 Kubernetes API 创建和存储策略。
- `--authorization-mode=Webhook` WebHook 是一种 HTTP 回调模式，允许你使用远程 REST 端点管理鉴权。
- `--authorization-mode=Node` 节点鉴权是一种特殊用途的鉴权模式，专门对 kubelet 发出的 API 请求执行鉴权。
- `--authorization-mode=AlwaysDeny` 该标志阻止所有请求。仅将此标志用于测试。
- `--authorization-mode=AlwaysAllow` 此标志允许所有请求。仅在你不需要 API 请求 的鉴权时才使用此标志。

与上一篇的认证模块不同的是，当配置多个鉴权模块时，鉴权模块按**顺序**检查，靠前的模块具有更高的优先级来允许或拒绝请求。

鉴权结果





## 公共库

### client-go

client-go 是 kubernetes 中比较重要的一个组件，从我上一篇文章中梳理的图中可以看出来，apiserver 是一个核心，其它组件都要和这个核心模块交互，所以 client-go 的出现就是为了统一封装对 apiserver 的交互访问。

client-go 这种设计思路还是不错的，当然是适合 kubernetes 这样的项目，几乎所有的模块都在围绕 apiserver，那么和 apiserver 的交互就显的尤为重要，那么这部分代码的抽象封装也就顺理成章了。这种解偶方式也是挺特别的，在看了书，走读了这部分的源码之后也才发现，同样的 client 在使用方式，使用对象不一样，就需要不一样的封装方式

| 目录名     | 用途                                                         |
| :--------- | :----------------------------------------------------------- |
| discovery  | 这个是 discovery client 的代码，是对 rest 客户端的进一步封装，用于发现 apiserver 所支持的能力和信息 |
| dynamic    | 这个是 dynamic client 的代码，是对 rest 客户端的进一步封装，动态客户端，面向处理 CRD |
| examples   | 这里面有一些例子，比如对 deployment 创建、修改，如何选主，workqueue 如何使用等等 |
| informers  | 这就是 client-go 中非常有名的 informer 机制的核心代码        |
| kubernetes | clientset 的代码，也是对 rest 客户端的进一步封装，提供复杂的资源访问和管理能力 |
| listers    | 为每个 k8s 资源提供 lister 功能，提供了只读缓存功能          |
| metadata   |                                                              |
| pkg        | 主要是一些功能函数，比如版本函数                             |
| rest       | 这是最基础的 client，其它的 client 都是基于此派生的          |
| scale      | scale client 的代码                                          |
| tools      | 工具函数库，主要是和 k8s 相关的工具函数                      |
| util       | 通用的一些工具函数                                           |
| transport  | 提供安全 tcp 链接                                            |

核心数据结构

```go
type RESTClient struct {
	// 这个初始化的 apiserver 的地址，下面我也贴了一个 kubeconfig 文件的内容，这个地址就是 cluster 的 server。
	base *url.URL

    // 这个是 apiVersion 
	versionedAPIPath string
    // 对客户端编解码的设置
	content ClientContentConfig

	// creates BackoffManager that is passed to requests.
	createBackoffMgr func() BackoffManager

    // 限流控制，是针对这个客户端的所有请求的。这个也是非常好的一个设计，一般 sdk 的设计很少考虑这个，大多数只考虑功能
	rateLimiter flowcontrol.RateLimiter

	// warningHandler is shared among all requests created by this client.
	// If not set, defaultWarningHandler is used.
	warningHandler WarningHandler

	// http 请求客户端
	Client *http.Client
}
```

#### informer

Informer (就是 SharedInformer)是 client-go 的重要组成部分，在了解 client-go 之前，了解一下 Informer 的实现是很有必要的

主要使用到 Informer 和 workqueue 两个核心组件。Controller 可以有一个或多个 informer 来跟踪某一个 resource。Informter 跟 API server 保持通讯获取资源的最新状态并更新到本地的 cache 中，一旦跟踪的资源有变化，informer 就会调用 callback。把关心的变更的 Object 放到 workqueue 里面。然后 woker 执行真正的业务逻辑，计算和比较 workerqueue 里 items 的当前状态和期望状态的差别，然后通过 client-go 向 API server 发送请求，直到驱动这个集群向用户要求的状态演化



### wait

代码路径: `vendor/k8s.io/apimachinery/pkg/util/wait/wait.go`

wait库内的各种function，大体来说都是以轮询的形式，根据时间间隔、条件判断，来确定工具执行函数是否应被继续执行。按代码中呈现，按触发形式再细化一下，各function则可以分为这几类

| 条件类型  | 说明                                                         |
| --------- | ------------------------------------------------------------ |
| Until类   | 用得最多的类型，一般以一条chan struct{} 或context Done接收done信号作为终止轮询的依据 |
| Backoff类 | 每间隔一定的时长执行一次回溯函数，一般情况下，间隔时长随着回溯次数递增而倍数级延长，但间隔时长也会有上限值 |
| poll类    | 两条channel，一条用作传递单次执行信号用来轮询，一条用作传递done信号 |

Untile类型有两个具体实现，分别是Until和UntilWithContext

```go
func Until(f func(), period time.Duration, stopCh <-chan struct{}) {
	JitterUntil(f, period, 0.0, true, stopCh)
}
```

JitterUntil函数可谓是把条件考虑得很细致，参数上有执行周期、抖动因子、窗口期(是否包含函数执行时间)，另外在stopCh信号处理上也做到了预防超期执行，JitterUntil函数已经足以应对各类以时间间隔维度的轮询场景了

UntilWithContext

```go
func UntilWithContext(ctx context.Context, f func(context.Context), period time.Duration) {
	JitterUntilWithContext(ctx, f, period, 0.0, true)
}
```

Backoff类

https://github.com/yinwenqin/kubeSourceCodeNote/blob/master/pkg/pkg-01-wait-%E5%AE%9A%E6%97%B6(%E6%9D%A1%E4%BB%B6)%E8%BD%AE%E8%AF%A2%E5%BA%93.md

## 资源

源码剖析：https://wqyin.cn/gitbooks/kubeSourceCodeNote/apiServer/Kubernetes%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0-APIServer-P1-%E5%9F%BA%E7%A1%80%E7%BB%93%E6%9E%84%E4%BF%A1%E6%81%AF.html

源码剖析：https://helight.cn/blog/2020/kube-controller-manager-code-1/

源码剖析：https://github.com/cloudnativeto/sig-kubernetes/blob/master/docs/event/code-club.md
